{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f6bb51a7-d089-432d-b19e-11a0f0cc8d3b",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "# Gaussian Copula Imputer\n",
    "Welcome to this tutorial on the **Gaussian Copula Imputer**!\n",
    "In this notebook, we demonstrate how to use the **Gaussian Copula Imputer** in Python.\n",
    "\n",
    "This method improves the Gaussian Conditional Imputer by handling more realistic data.  \n",
    "Instead of assuming that all features follow a normal distribution, it uses the actual distribution of each feature and models their dependencies with a Gaussian copula.\n",
    "\n",
    "## Table of Contents\n",
    "1. What is a Gaussian Copula Imputer?\n",
    "2. Why do we need it?\n",
    "3. How does the implementation work?\n",
    "4. Example usage\n",
    "5.  Summary\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c585bcb-32b7-47a7-9f8f-9e3572525562",
   "metadata": {},
   "source": [
    "## 1. What is a Gaussian Copula Imputer?\n",
    "\n",
    "- Goal: Realistically impute missing feature values\n",
    "- Approach: Transform data into the Gaussian space using ECDFs (Empirical Cumulative Distribution Functions)\n",
    "- Impute missing values conditinally asssuming a multivariate Gaussian in z-space\n",
    "- Inverse transform to original feature space using inverse ECDFs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2361a406-c010-40af-a33a-9cb01f567540",
   "metadata": {},
   "source": [
    "## 2. Why do we need it?\n",
    "- Many classical methods (e.g., `shap`) assume feature independence\n",
    "- → Leads to biased or unrealistic imputations\n",
    "- Real-world data often contains dependencies between features\n",
    "- The Gaussian Copula Imputer models those dependencies via the correlation structure in z-space\n",
    "- → Result: more realistic imputations and more accurate Shapley values"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a121e72b-4cd0-4a19-932e-d54750034162",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "## 3. How does the implementation work?\n",
    "In this case section, we walk through the implementation of the `GaussianCopulaImputer` class step by step.\n",
    "This class extends the `Imputer` interface from the `shapiq` framework and applies Gaussian Copula theory to impute missing values"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c99b367-a26b-4a51-a199-5525f6288e0d",
   "metadata": {},
   "source": [
    "### 3.1 Imports and Class Overview\n",
    "First we import the required libraries and outline the overall structure of the `GaussianCopulaImputer` class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "85c491b3-d20a-41e6-8a9a-47a92794c0d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy.stats import multivariate_normal, norm\n",
    "from numpy.linalg import pinv\n",
    "from shapiq.games.imputer.base import Imputer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bdc1808b-29aa-425d-b0f1-7d9a13af8c20",
   "metadata": {},
   "source": [
    "### 3.2 Constructor (`__init__`)\n",
    "The constructor initializes the imputer with a model, input data, and an optional reference instance `x`.\n",
    "It also prepares the structures for the ECDF transformations and the correlation matrix in Gaussian space."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9ca4691d-3493-404f-9aa6-d9c859d33d48",
   "metadata": {},
   "outputs": [],
   "source": [
    "class GaussianCopulaImputer(Imputer):\n",
    "    def __init__(self, model=None, data=None, x=None):\n",
    "        super().__init__(model=model, data=data)\n",
    "        self._x_internal = x\n",
    "        self.ecdfs = []\n",
    "        self.inverse_ecdfs = []\n",
    "        self.transformed_data = None\n",
    "        self.correlation = None"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f965211-35e1-42cc-a237-6d8182cbd354",
   "metadata": {},
   "source": [
    "### 3.3 Fitting the Imputer (`fit` method)\n",
    "The `fit()` method transforms the data into Gaussian (z) space using ECDFs (Empirical Cumulative Distribution Functions). It stores:\n",
    "- CDF and inverse ECDF for each feature\n",
    "- Transformed data in z-space\n",
    "- The correlation matrix in z-space\n",
    "\n",
    "This step is essential before imputation can be done."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "92f5d79f-f5e5-46a5-b537-9117c5900383",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit(self, x: np.ndarray) -> None:\n",
    "    self._x_internal = x\n",
    "    x = np.asarray(x)\n",
    "    n, d = x.shape\n",
    "    self.ecdfs = []\n",
    "    self.inverse_ecdfs = []\n",
    "    z_data = np.zeros_like(x)\n",
    "\n",
    "    for j in range(d):\n",
    "        col = x[:, j]\n",
    "        sorted_col = np.sort(col)\n",
    "\n",
    "        def ecdf_func(x_val: float, sorted_col=sorted_col) -> float:\n",
    "            return float(np.searchsorted(sorted_col, x_val, side=\"right\") / len(sorted_col))\n",
    "\n",
    "        def inverse_ecdf_func(p: float, sorted_col=sorted_col) -> float:\n",
    "            p = np.clip(p, 1e-6, 1 - 1e-6)\n",
    "            idx = np.round(p * (len(sorted_col) - 1)).astype(int)\n",
    "            return sorted_col[idx]\n",
    "\n",
    "        self.ecdfs.append(ecdf_func)\n",
    "        self.inverse_ecdfs.append(inverse_ecdf_func)\n",
    "\n",
    "        u = np.array([ecdf_func(xi) for xi in col])\n",
    "        u = np.clip(u, 1e-6, 1 - 1e-6)\n",
    "        z = norm.ppf(u)\n",
    "        z_data[:, j] = z\n",
    "\n",
    "    self.transformed_data = z_data\n",
    "    with np.errstate(divide=\"ignore\", invalid=\"ignore\"):\n",
    "        corr = np.corrcoef(z_data, rowvar=False)\n",
    "        corr = np.nan_to_num(corr, nan=0.0, posinf=0.0, neginf=0.0)\n",
    "\n",
    "    self.correlation = corr"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29290b6c-d7dd-4b66-8852-71c0902dff0a",
   "metadata": {},
   "source": [
    "### 3.4 Imputing Missing Values (`impute` method)\n",
    "This method performs the actual imputation using the Gaussian copula.\n",
    "Steps:\n",
    "1. Transform known features into z-space using ECDFs.\n",
    "2. Compute conditional mean and covariance in z-space.\n",
    "3. Sample missing features from the conditional distribution.\n",
    "4. Transform sampled values back to original space using inverse ECDFs.\n",
    "\n",
    "This allows imputing missing features based on the known ones while preserving feature dependencies."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a3b803a9-55fc-4ffb-83b4-4f623f58e3d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def impute(\n",
    "    self, x_known: np.ndarray, known_idx: list[int], missing_idx: list[int]\n",
    ") -> np.ndarray:\n",
    "    z_known = np.array([\n",
    "        norm.ppf(np.clip(self.ecdfs[idx](x_known[i]), 1e-6, 1 - 1e-6))\n",
    "        for i, idx in enumerate(known_idx)\n",
    "    ])\n",
    "\n",
    "    assert self.correlation is not None, \"Correlation matrix must be computed before imputation.\"\n",
    "\n",
    "    Sigma = self.correlation\n",
    "    Sigma_SS = Sigma[np.ix_(known_idx, known_idx)]\n",
    "    Sigma_barS_S = Sigma[np.ix_(missing_idx, known_idx)]\n",
    "    Sigma_barS_barS = Sigma[np.ix_(missing_idx, missing_idx)]\n",
    "    Sigma_S_barS = Sigma_barS_S.T\n",
    "\n",
    "    mu_S = np.zeros(len(known_idx))\n",
    "    mu_barS = np.zeros(len(missing_idx))\n",
    "    delta = z_known - mu_S\n",
    "    inv_Sigma_SS = pinv(Sigma_SS)\n",
    "\n",
    "    z_barS_cond_mean = mu_barS + Sigma_barS_S @ inv_Sigma_SS @ delta\n",
    "    z_barS_cond_cov = Sigma_barS_barS - Sigma_barS_S @ inv_Sigma_SS @ Sigma_S_barS\n",
    "\n",
    "    z_missing = multivariate_normal(\n",
    "        mean=z_barS_cond_mean, cov=z_barS_cond_cov, allow_singular=True\n",
    "    ).rvs()\n",
    "\n",
    "    if len(missing_idx) == 1:\n",
    "        z_missing = np.array([z_missing])\n",
    "\n",
    "    x_missing = []\n",
    "    for i, idx in enumerate(missing_idx):\n",
    "        inv_ecdf = self.inverse_ecdfs[idx]\n",
    "        percentile = norm.cdf(z_missing[i])\n",
    "        x_val = inv_ecdf(percentile)\n",
    "        x_missing.append(x_val)\n",
    "\n",
    "    return np.array(x_missing)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2c4d198-3395-492d-a893-bb6ec490e8dc",
   "metadata": {},
   "source": [
    "### 3.5 Predicting with Coalitions (`__call__` method)\n",
    "This method evaluates the model's output for different coalitions (feature subsets).\n",
    "Each coalition is a binary vector indicating which features are known (1) and which are missing (0).\n",
    "Steps:\n",
    "1. Identify known and missing feature indices.\n",
    "2. Impute missing features using the `impute` method.\n",
    "3. Construct a full feature vector and predict the model output.\n",
    "\n",
    "If no features are known, the model returns `0.0`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b8bf89ef-d184-4e12-acd7-42e2f87c92c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def __call__(self, coalitions: np.ndarray) -> np.ndarray:\n",
    "    values = []\n",
    "    for coalition in coalitions:\n",
    "        known_idx = list(np.where(coalition)[0])\n",
    "        missing_idx = list(np.where(~coalition)[0])\n",
    "\n",
    "        if len(known_idx) == 0:\n",
    "            values.append(0.0)\n",
    "            continue\n",
    "\n",
    "        assert self.x is not None, \"Reference instance x must be set before calling imputer.\"\n",
    "\n",
    "        x_known = self.x[0, known_idx]\n",
    "        x_imputed = self.impute(x_known, known_idx, missing_idx)\n",
    "\n",
    "        full_x = np.zeros(self.x.shape[1])\n",
    "        full_x[known_idx] = x_known\n",
    "        full_x[missing_idx] = x_imputed\n",
    "\n",
    "        values.append(float(self.predict(full_x.reshape(1, -1))[0]))\n",
    "\n",
    "    return np.array(values)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd0ea4e9-d5bd-419e-aaec-426e00457094",
   "metadata": {},
   "source": [
    "## 4. Example Usage\n",
    "We now demonstrate how to use the `GaussianCopulaImputer` with synthetic data and a simple dummy model."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a04d59d8-af62-4949-ad8d-dd142dcc8e35",
   "metadata": {},
   "source": [
    "### 4.1 Generate synthetic data and set up the imputer\n",
    "We create a simple dataset of 100 samples and 5 features from a normal distribution, and define a dummy model that sums feature values. Then we initialize and fit the imputer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7a6e4d7-fcc8-4e5f-a0c3-b9ff423d8a9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "#from shapiq_student.gaussian_copula_imputer import GaussianCopulaImputer\n",
    "from gaussian_copula_imputer import GaussianCopulaImputer\n",
    "\n",
    "class DummyModel:\n",
    "    def __call__(self, X: np.ndarray) -> np.ndarray:\n",
    "        return np.sum(X, axis=1)\n",
    "    \n",
    "    def predict(self, X: np.ndarray) -> np.ndarray:\n",
    "        return np.sum(X, axis=1)\n",
    "\n",
    "rng = np.random.default_rng(42)\n",
    "data = rng.normal(loc=0, scale=1, size=(100, 5))\n",
    "model = DummyModel()\n",
    "\n",
    "imputer = GaussianCopulaImputer(model=model, data=data)\n",
    "imputer.fit(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea53bbce-676f-4b01-9339-ea025960dfe6",
   "metadata": {},
   "source": [
    "### 4.2 Impute missing values for a specific instance\n",
    "We simulate a scenario where some features are missing and use the imputer to fill them in."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "434814a0-991f-44ea-b48b-2a2ba85d4132",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_sample = data[0, :]\n",
    "known_idx = [0, 1, 3]\n",
    "missing_idx = [2, 4]\n",
    "\n",
    "x_known = x_sample[known_idx]\n",
    "x_imputed = imputer.impute(x_known, known_idx, missing_idx)\n",
    "\n",
    "print(\"Known values:\", x_known)\n",
    "print(\"Imputed values:\", x_imputed)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8429c3e0-c06a-44e0-87d2-a5092866358a",
   "metadata": {},
   "source": [
    "### 4.3 Predict outcomes using feature coalitions\n",
    "We provide coalitions (which features are known) and use the imputer to predict model outputs accordingly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "400fac25-2f79-4e10-840e-fa690affd119",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_ref = data[[0], :]\n",
    "imputer._x_internal = x_ref\n",
    "\n",
    "coalitions = rng.integers(0, 2, size=(5, 5))\n",
    "\n",
    "predictions = imputer(coalitions)\n",
    "\n",
    "print(\"Coalitions:\\n\", coalitions)\n",
    "print(\"Predicted outputs:\", predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f3e547f-c966-423a-81dd-70fb77aeb749",
   "metadata": {},
   "source": [
    "## 5. Summary\n",
    "In this notebook, we explored the **Gaussian Copula Imputer**, a method for imputing missing feature values by:\n",
    "\n",
    "- Transforming data into a Gaussian space using **ECDFs**\n",
    "- Modeling dependencies via a **correlation matrix** in z-space\n",
    "- Sampling missing values from a **conditional multivariate normal distribution**\n",
    "- Transforming the imputed values back to the original feature space\n",
    "\n",
    "Compared to methods that assume feature independence, this approach:\n",
    "- Produces more realistic imputations\n",
    "- Preserves dependencies between features\n",
    "- Leads to more reliable results, especially in explainable AI settings (e.g., computing Shapley values)\n",
    "\n",
    "The Gaussian Copula Imputer is a powerful tool for handling missing data in correlated datasets."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
